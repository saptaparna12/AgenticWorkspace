{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d59c27d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!pip install langchain \n",
    "!pip uninstall langchain langchain-core -y\n",
    "!pip install langchain==0.3.27 langchain-core==0.3.72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7e7e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain langgraph-prebuilt langchain-huggingface\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3cfd6439",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "##define the template for the stance classification task\n",
    "stance_template = \"\"\"\n",
    "Please classify the stance, or the opinion, of the following reply to the comment.\n",
    "Note that we want the stance of the reply to the comment, and not to the stance of the reply to the topic of the comment.\n",
    "Only give the stance as \"agree\",\"disagree\" or \"neutral\" and output no other words after outputting the label.\n",
    "comment: {comment}\n",
    "reply: {reply}\n",
    "stance:\"\"\"\n",
    "\n",
    "#Create the prompt template object\n",
    "stance_prompt = PromptTemplate(input_variables=[\"comment\",\"reply\"],template=stance_template)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "793a7880",
   "metadata": {},
   "outputs": [],
   "source": [
    "comment = \"I think this topic is very important for the community.\"\n",
    "reply = \"I agree with you, It's crucial to address these issues.\"\n",
    "\n",
    "formatted_prompt = stance_prompt.format(comment=comment , reply=reply)\n",
    "print(formatted_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0baa558",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers \n",
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb259b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFacePipeline\n",
    "from transformers import pipeline\n",
    "\n",
    "#load the hugging face text generation pipeline with specified model\n",
    "hf_pipeline = pipeline(\n",
    "    \"text-generation\",\n",
    "     model=\"tiiuae/Falcon3-1b-Instruct\",\n",
    "     device=-1, #0 for gpu , -1 for cpu\n",
    "     max_new_tokens=500, #limit the max token generated to 500\n",
    "     return_full_text=False #only output the generated text not the prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f390d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " neutral.\n",
      "The answer is: neutral.\n"
     ]
    }
   ],
   "source": [
    "llm = HuggingFacePipeline(pipeline=hf_pipeline)\n",
    "\n",
    "prompt = \"Please classify the stance, or the opinion, of the following reply to the comment: comment: 'this is a very important issue.' reply: 'I completely agree!', stance:\"\n",
    "\n",
    "generated_output = llm.invoke(prompt)\n",
    "print(generated_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "66c191ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classified Stance:  agree\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stance_chain = stance_prompt | llm\n",
    "\n",
    "#example comment and reply\n",
    "comment = \"I think this topic is very important for the community.\"\n",
    "reply = \"I agree with you, It's crucial to address these issues.\"\n",
    "\n",
    "#invoke the chain to classify the stance\n",
    "generated_output = stance_chain.invoke({\"comment\":comment,\"reply\": reply})\n",
    "\n",
    "#output the result. (will print only the generated text)\n",
    "print(\"Classified Stance:\", generated_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb712dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_comment = \"The new Dune movie does not really capture the vision laid out by Frank Herbert. It feels like they tried to import too many visual effects that take away from the philosophy of the work.\"\n",
    "\n",
    "test_replies = [\n",
    "    \"The newer ones fail to live up to the sophistry of the older movies from the 70's.\",\n",
    "    \"Frank Herbert wrote a lot of books.\",\n",
    "    \"I think the new Dune movie better captures the spirit, if not the content, of Frank Herbert's philosophy.\",\n",
    "    \"The quick red fox jumped over the lazy brown dog.\",\n",
    "    \"Yeah, this new movie is a real masterpiece, lol!!\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "13d22c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reply: The newer ones fail to live up to the sophistry of the older movies from the 70's.\n",
      "Stance:  disagree\n",
      "\n",
      "<|assistant|>\n",
      "neutral\n",
      "\n",
      "\n",
      "\n",
      "Reply: Frank Herbert wrote a lot of books.\n",
      "Stance:  neutral.\n",
      "\n",
      "Reply: I think the new Dune movie better captures the spirit, if not the content, of Frank Herbert's philosophy.\n",
      "Stance:  disagree\n",
      "\n",
      "\n",
      "Reply: The quick red fox jumped over the lazy brown dog.\n",
      "Stance:  neutral\n",
      "\n",
      "\n",
      "Reply: Yeah, this new movie is a real masterpiece, lol!!\n",
      "Stance:  neutral\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results=[]\n",
    "\n",
    "for reply in test_replies:\n",
    "    #invoke the chain for each reply and store the result\n",
    "    result = stance_chain.invoke({\"comment\": test_comment,\"reply\": reply})\n",
    "    results.append(result)\n",
    "    \n",
    "#print the results\n",
    "for reply, result in zip(test_replies, results):\n",
    "    print(f\"Reply: {reply}\\nStance: {result}\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c4a7a08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import FewShotPromptTemplate\n",
    "#define the prompt template for each example\n",
    "example_template='''comment: {comment},\n",
    "reply: {reply},\n",
    "stance: {stance}'''\n",
    "\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"comment\",\"reply\", \"stance\"],\n",
    "    template=example_template\n",
    ")\n",
    "\n",
    "#define the examples with various stances\n",
    "examples = [\n",
    "    {\"comment\": \"I think the new policy will help improve efficiency.\",\n",
    "     \"reply\": \"I agree, it will make things more streamlined.\",\n",
    "     \"stance\": \"agree\"},\n",
    "    \n",
    "    {\"comment\": \"The new education reform seems promising.\",\n",
    "     \"reply\": \"I disagree, it doesn't address the underlying issues.\",\n",
    "     \"stance\": \"disagree\"},\n",
    "    \n",
    "    {\"comment\": \"The park renovation project is a good idea.\",\n",
    "     \"reply\": \"I'm not sure. It may be good, but the location is an issue.\",\n",
    "     \"stance\": \"neutral\"},\n",
    "    \n",
    "    {\"comment\": \"Artificial intelligence will revolutionize healthcare.\",\n",
    "     \"reply\": \"I agree, it has the potential to save many lives.\",\n",
    "     \"stance\": \"agree\"},\n",
    "    \n",
    "    {\"comment\": \"The economy is showing signs of recovery after the pandemic.\",\n",
    "     \"reply\": \"I disagree, the recovery seems to be slow and uneven.\",\n",
    "     \"stance\": \"disagree\"},\n",
    "]\n",
    "\n",
    "# Define the prefix and suffix for the few-shot prompt\n",
    "prefix = \"\"\"Stance classification is the task of determining the expressed or implied opinion, or stance, of a reply toward a comment. The following replies express opinions about the associated comment. Each reply can either be \"agree\",\"disagree\" or \"neutral\" and output no other words after outputting the label.\"\"\"\n",
    "suffix = \"\"\"Analyze the following reply to the provided comment and determine its stance. Respond with a single word: \"agree\", \"disagree\", or \"neutral\". Only return the stance as a single word, and no other text.\n",
    "Comment: {comment}\n",
    "Reply: {reply}\n",
    "Stance:\"\"\"\n",
    "\n",
    "# Create the FewShotPromptTemplate using the provided prefix, suffix, and examples\n",
    "few_shot_prompt = FewShotPromptTemplate(\n",
    "            examples=examples,\n",
    "            example_prompt=example_prompt,\n",
    "            prefix=prefix,\n",
    "            suffix=suffix,\n",
    "            input_variables=[\"comment\",\"reply\"],\n",
    "            example_separator=\"\\n\"\n",
    "    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "82bbf3ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stance classification is the task of determining the expressed or implied opinion, or stance, of a reply toward a comment. The following replies express opinions about the associated comment. Each reply can either be \"agree\",\"disagree\" or \"neutral\" and output no other words after outputting the label.\n",
      "comment: I think the new policy will help improve efficiency.,\n",
      "reply: I agree, it will make things more streamlined.,\n",
      "stance: agree\n",
      "comment: The new education reform seems promising.,\n",
      "reply: I disagree, it doesn't address the underlying issues.,\n",
      "stance: disagree\n",
      "comment: The park renovation project is a good idea.,\n",
      "reply: I'm not sure. It may be good, but the location is an issue.,\n",
      "stance: neutral\n",
      "comment: Artificial intelligence will revolutionize healthcare.,\n",
      "reply: I agree, it has the potential to save many lives.,\n",
      "stance: agree\n",
      "comment: The economy is showing signs of recovery after the pandemic.,\n",
      "reply: I disagree, the recovery seems to be slow and uneven.,\n",
      "stance: disagree\n",
      "Analyze the following reply to the provided comment and determine its stance. Respond with a single word: \"agree\", \"disagree\", or \"neutral\". Only return the stance as a single word, and no other text.\n",
      "Comment: I think this topic is very important for the community.\n",
      "Reply: Yeah, this new movie is a real masterpiece, lol!!\n",
      "Stance:\n"
     ]
    }
   ],
   "source": [
    "print(few_shot_prompt.format(comment=comment, reply=reply))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "792ca2af",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-3938488962.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mresponses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_replies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Reply [idx+1]: {reply}\\nStance: {response}\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "few_shot_chain = few_shot_prompt | llm\n",
    "\n",
    "responses=[]\n",
    "for reply in test_replies:\n",
    "    response=few_shot_chain.invoke({\"comment\": test_comment, \"reply\": reply})\n",
    "    responses.append(response)\n",
    "\n",
    "for idx, (reply, result) in zip(test_replies, responses):\n",
    "    print(f\"Reply [idx+1]: {reply}\\nStance: {response}\\n\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
